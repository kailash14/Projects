{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HUMAN ACTIVITY RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing necessry libararies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "import keras\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(23)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture of LSTM WITH ONE LAYER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH 32 LSTM UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden,kernel_initializer='glorot_uniform',kernel_regularizer=keras.regularizers.l2(0.01),input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 1.3438 - acc: 0.4415 - val_loss: 1.2514 - val_acc: 0.5110\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 1.1137 - acc: 0.5260 - val_loss: 1.1821 - val_acc: 0.5195\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.9173 - acc: 0.6646 - val_loss: 0.8440 - val_acc: 0.7194\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.7092 - acc: 0.7582 - val_loss: 0.7426 - val_acc: 0.7462\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.6015 - acc: 0.8071 - val_loss: 0.6821 - val_acc: 0.7937\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 37s 5ms/step - loss: 0.5019 - acc: 0.8496 - val_loss: 0.5336 - val_acc: 0.8351\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 37s 5ms/step - loss: 0.4343 - acc: 0.8726 - val_loss: 0.6805 - val_acc: 0.8120\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 37s 5ms/step - loss: 0.5193 - acc: 0.8539 - val_loss: 0.5065 - val_acc: 0.8592\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 37s 5ms/step - loss: 0.3748 - acc: 0.8890 - val_loss: 0.4503 - val_acc: 0.8568\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.3565 - acc: 0.8921 - val_loss: 0.4806 - val_acc: 0.8643\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.3784 - acc: 0.8992 - val_loss: 0.4103 - val_acc: 0.8680\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.3526 - acc: 0.9055 - val_loss: 0.5987 - val_acc: 0.8504\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.3359 - acc: 0.9026 - val_loss: 0.2677 - val_acc: 0.9118\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.3330 - acc: 0.9085 - val_loss: 0.4727 - val_acc: 0.8663\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.3033 - acc: 0.9180 - val_loss: 0.3288 - val_acc: 0.8965\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.3478 - acc: 0.9048 - val_loss: 0.3491 - val_acc: 0.8867\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.6600 - acc: 0.8290 - val_loss: 0.8008 - val_acc: 0.7323\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 0.4170 - acc: 0.8726 - val_loss: 0.4929 - val_acc: 0.8643\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.3222 - acc: 0.9128 - val_loss: 0.4737 - val_acc: 0.8565\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 0.2884 - acc: 0.9095 - val_loss: 0.3343 - val_acc: 0.8935\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.2800 - acc: 0.9214 - val_loss: 0.4827 - val_acc: 0.8755\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.2971 - acc: 0.9173 - val_loss: 0.3264 - val_acc: 0.8911\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 47s 6ms/step - loss: 0.2559 - acc: 0.9261 - val_loss: 0.3073 - val_acc: 0.9006\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.2714 - acc: 0.9218 - val_loss: 0.3514 - val_acc: 0.8785\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2778 - acc: 0.9192 - val_loss: 0.2562 - val_acc: 0.9108\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.2567 - acc: 0.9244 - val_loss: 0.3439 - val_acc: 0.9006\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2775 - acc: 0.9203 - val_loss: 0.5383 - val_acc: 0.8504\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 40s 5ms/step - loss: 0.2717 - acc: 0.9232 - val_loss: 0.3291 - val_acc: 0.9040\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.3412 - acc: 0.9174 - val_loss: 0.3604 - val_acc: 0.8914\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.2679 - acc: 0.9202 - val_loss: 0.3904 - val_acc: 0.8948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201fabeb8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  5      372       112        2                   0   \n",
      "STANDING                 0       86       444        2                   0   \n",
      "WALKING                  3        0         0      483                   0   \n",
      "WALKING_DOWNSTAIRS       0        0         0       10                 395   \n",
      "WALKING_UPSTAIRS         7        6         1       51                   0   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                           10  \n",
      "WALKING_DOWNSTAIRS                15  \n",
      "WALKING_UPSTAIRS                 406  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 2s 607us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3903591258076538, 0.8948082796063793]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH 64 LSTM UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_steps, n_length = 4, 32\n",
    "#X_train = X_train.reshape((X_train.shape[0], n_steps, n_length, input_dim))\n",
    "#X_test = X_test.reshape((X_test.shape[0], n_steps, n_length, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 64)                18944     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 19,334\n",
      "Trainable params: 19,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden,kernel_initializer='glorot_uniform', input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 57s 8ms/step - loss: 1.1235 - acc: 0.5223 - val_loss: 1.0438 - val_acc: 0.5636\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 55s 7ms/step - loss: 0.7175 - acc: 0.7055 - val_loss: 1.4433 - val_acc: 0.6013\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.5717 - acc: 0.8044 - val_loss: 0.5565 - val_acc: 0.8334\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.3381 - acc: 0.8908 - val_loss: 0.3908 - val_acc: 0.8622\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 55s 7ms/step - loss: 0.2398 - acc: 0.9192 - val_loss: 0.4973 - val_acc: 0.8717\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.2284 - acc: 0.9275 - val_loss: 0.5707 - val_acc: 0.8558\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.2063 - acc: 0.9378 - val_loss: 0.4014 - val_acc: 0.8694\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 56s 8ms/step - loss: 0.1883 - acc: 0.9369 - val_loss: 0.3061 - val_acc: 0.9006\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1753 - acc: 0.9406 - val_loss: 0.3416 - val_acc: 0.9091\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1839 - acc: 0.9411 - val_loss: 0.3342 - val_acc: 0.9002\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1535 - acc: 0.9431 - val_loss: 0.3110 - val_acc: 0.9036\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.1540 - acc: 0.9448 - val_loss: 0.5049 - val_acc: 0.8924\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1628 - acc: 0.9423 - val_loss: 0.3473 - val_acc: 0.9121\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1820 - acc: 0.9449 - val_loss: 0.3299 - val_acc: 0.9070\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1531 - acc: 0.9478 - val_loss: 0.3605 - val_acc: 0.9002\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1461 - acc: 0.9478 - val_loss: 0.5520 - val_acc: 0.8918\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1511 - acc: 0.9493 - val_loss: 0.6150 - val_acc: 0.8911\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1472 - acc: 0.9479 - val_loss: 0.5592 - val_acc: 0.9023\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 56s 8ms/step - loss: 0.1328 - acc: 0.9512 - val_loss: 0.5159 - val_acc: 0.9019\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1426 - acc: 0.9487 - val_loss: 0.4793 - val_acc: 0.8948\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 56s 8ms/step - loss: 0.1418 - acc: 0.9474 - val_loss: 0.3662 - val_acc: 0.9125\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1670 - acc: 0.9442 - val_loss: 0.4876 - val_acc: 0.8921\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1695 - acc: 0.9491 - val_loss: 0.4928 - val_acc: 0.8958\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.1634 - acc: 0.9479 - val_loss: 0.4534 - val_acc: 0.8945\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1408 - acc: 0.9489 - val_loss: 0.6674 - val_acc: 0.8948\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1501 - acc: 0.9493 - val_loss: 0.6079 - val_acc: 0.8948\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1650 - acc: 0.9490 - val_loss: 0.7819 - val_acc: 0.8897\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.1619 - acc: 0.9498 - val_loss: 0.6143 - val_acc: 0.9009\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.1541 - acc: 0.9486 - val_loss: 0.6079 - val_acc: 0.9033\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 48s 7ms/step - loss: 0.2033 - acc: 0.9431 - val_loss: 0.4655 - val_acc: 0.8941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x201f97e10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0        25        0                   0   \n",
      "SITTING                  0      388       100        0                   0   \n",
      "STANDING                 0      110       421        1                   0   \n",
      "WALKING                  0        0         0      455                  14   \n",
      "WALKING_DOWNSTAIRS       0        0         1        0                 412   \n",
      "WALKING_UPSTAIRS         0        1         3        5                  13   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             2  \n",
      "SITTING                            3  \n",
      "STANDING                           0  \n",
      "WALKING                           27  \n",
      "WALKING_DOWNSTAIRS                 7  \n",
      "WALKING_UPSTAIRS                 449  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 3s 921us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46545276161816074, 0.8941296233457754]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH 128 LSTM UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128)               70656     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 71,430\n",
      "Trainable params: 71,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden,kernel_initializer='glorot_uniform', input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 90s 12ms/step - loss: 1.1401 - acc: 0.5316 - val_loss: 0.8731 - val_acc: 0.6284\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.6759 - acc: 0.7282 - val_loss: 0.6944 - val_acc: 0.7733\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.4599 - acc: 0.8429 - val_loss: 0.4666 - val_acc: 0.8588\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.2931 - acc: 0.9070 - val_loss: 0.3649 - val_acc: 0.8700\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.3860 - acc: 0.8692 - val_loss: 0.5013 - val_acc: 0.8154\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.4117 - acc: 0.8690 - val_loss: 0.4298 - val_acc: 0.8578\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.2912 - acc: 0.9047 - val_loss: 0.3491 - val_acc: 0.8724\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.2914 - acc: 0.9090 - val_loss: 0.7513 - val_acc: 0.7190\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.7469 - acc: 0.6960 - val_loss: 0.3682 - val_acc: 0.8700\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.2246 - acc: 0.9252 - val_loss: 0.5502 - val_acc: 0.8229\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.6188 - acc: 0.7779 - val_loss: 0.7220 - val_acc: 0.7153\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 1.0948 - acc: 0.6264 - val_loss: 1.4636 - val_acc: 0.4394\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 1.3889 - acc: 0.4434 - val_loss: 1.0401 - val_acc: 0.5565\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 1.2030 - acc: 0.5030 - val_loss: 1.0299 - val_acc: 0.5460\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.8966 - acc: 0.5926 - val_loss: 0.8082 - val_acc: 0.6932\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.7999 - acc: 0.6333 - val_loss: 0.7761 - val_acc: 0.6844\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.7421 - acc: 0.6819 - val_loss: 0.6778 - val_acc: 0.6966\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.7547 - acc: 0.6751 - val_loss: 0.6234 - val_acc: 0.7866\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.5266 - acc: 0.8001 - val_loss: 0.5801 - val_acc: 0.8073\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.6146 - acc: 0.7542 - val_loss: 0.6334 - val_acc: 0.7693\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.4621 - acc: 0.8452 - val_loss: 0.3604 - val_acc: 0.8799\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.3022 - acc: 0.8974 - val_loss: 0.3140 - val_acc: 0.8870\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.3253 - acc: 0.8863 - val_loss: 0.3177 - val_acc: 0.8819\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2350 - acc: 0.9176 - val_loss: 0.3021 - val_acc: 0.8911\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2479 - acc: 0.9116 - val_loss: 0.3209 - val_acc: 0.8816\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2276 - acc: 0.9173 - val_loss: 0.3162 - val_acc: 0.8979\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1769 - acc: 0.9368 - val_loss: 0.3455 - val_acc: 0.8890\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.2444 - acc: 0.9108 - val_loss: 0.3527 - val_acc: 0.8968\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.2049 - acc: 0.9242 - val_loss: 0.3840 - val_acc: 0.8748\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1848 - acc: 0.9305 - val_loss: 0.3159 - val_acc: 0.8989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20392b8d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 511        0        13       13                   0   \n",
      "SITTING                  0      353       137        0                   0   \n",
      "STANDING                 0       41       489        2                   0   \n",
      "WALKING                  0        0         0      464                   8   \n",
      "WALKING_DOWNSTAIRS       0        0         0       12                 397   \n",
      "WALKING_UPSTAIRS         0        1         2       33                   0   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            1  \n",
      "STANDING                           0  \n",
      "WALKING                           24  \n",
      "WALKING_DOWNSTAIRS                11  \n",
      "WALKING_UPSTAIRS                 435  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3158544494973829, 0.8988802171700034]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with Dropout 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 256\n",
    "n_hidden = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 128)               70656     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 71,430\n",
      "Trainable params: 71,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden,kernel_initializer='glorot_uniform', input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.4))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 1.4212 - acc: 0.3715 - val_loss: 1.3190 - val_acc: 0.3482\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 1.3187 - acc: 0.4188 - val_loss: 1.2344 - val_acc: 0.4469\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 46s 6ms/step - loss: 1.1797 - acc: 0.4795 - val_loss: 1.2065 - val_acc: 0.4601\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 1.1811 - acc: 0.4853 - val_loss: 1.2274 - val_acc: 0.4659\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 1.1110 - acc: 0.5185 - val_loss: 1.2072 - val_acc: 0.4859\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 1.0865 - acc: 0.5284 - val_loss: 1.1120 - val_acc: 0.5684\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 1.0423 - acc: 0.5396 - val_loss: 1.0371 - val_acc: 0.5436\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.8918 - acc: 0.5966 - val_loss: 0.9451 - val_acc: 0.5633\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.7843 - acc: 0.6212 - val_loss: 0.8636 - val_acc: 0.5972\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.7839 - acc: 0.6254 - val_loss: 0.9033 - val_acc: 0.5843\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.7728 - acc: 0.6266 - val_loss: 0.9567 - val_acc: 0.5433\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.7522 - acc: 0.6308 - val_loss: 0.8719 - val_acc: 0.5935\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.7874 - acc: 0.6192 - val_loss: 0.9084 - val_acc: 0.5864\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 1.0336 - acc: 0.5367 - val_loss: 0.9065 - val_acc: 0.5548\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.7830 - acc: 0.6177 - val_loss: 0.8376 - val_acc: 0.5898\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 55s 7ms/step - loss: 0.6811 - acc: 0.6566 - val_loss: 0.9068 - val_acc: 0.5752\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.7366 - acc: 0.6464 - val_loss: 1.0952 - val_acc: 0.5660\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.7116 - acc: 0.6575 - val_loss: 0.8158 - val_acc: 0.6101\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.6757 - acc: 0.6649 - val_loss: 0.7428 - val_acc: 0.6193\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.6026 - acc: 0.7057 - val_loss: 0.6640 - val_acc: 0.6990\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.5745 - acc: 0.7437 - val_loss: 0.6115 - val_acc: 0.7092\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.6534 - acc: 0.7437 - val_loss: 0.7113 - val_acc: 0.6451\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.5570 - acc: 0.7866 - val_loss: 0.7434 - val_acc: 0.7492\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.4908 - acc: 0.8203 - val_loss: 0.4946 - val_acc: 0.8317\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.4615 - acc: 0.8312 - val_loss: 0.4728 - val_acc: 0.8354\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.3621 - acc: 0.8785 - val_loss: 0.4718 - val_acc: 0.8456\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.3517 - acc: 0.8807 - val_loss: 0.4123 - val_acc: 0.8432\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.3370 - acc: 0.8804 - val_loss: 0.4319 - val_acc: 0.8334\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.2651 - acc: 0.9115 - val_loss: 0.7993 - val_acc: 0.7896\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.2943 - acc: 0.9026 - val_loss: 0.3384 - val_acc: 0.8782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20eff0320>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0        27        0                   0   \n",
      "SITTING                  2      408        81        0                   0   \n",
      "STANDING                 0      119       411        0                   0   \n",
      "WALKING                  0        1         0      448                  28   \n",
      "WALKING_DOWNSTAIRS       0        0         0        3                 403   \n",
      "WALKING_UPSTAIRS         0        0         2       29                  32   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            0  \n",
      "STANDING                           2  \n",
      "WALKING                           19  \n",
      "WALKING_DOWNSTAIRS                14  \n",
      "WALKING_UPSTAIRS                 408  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 7s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3383634945306286, 0.8781812012215813]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture of LSTM WITH TWO LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden1 = 32\n",
    "n_hidden2 =20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 128, 32)           5376      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 20)                4240      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 126       \n",
      "=================================================================\n",
      "Total params: 9,742\n",
      "Trainable params: 9,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden1,kernel_initializer='glorot_uniform', return_sequences=True,input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(n_hidden2,kernel_initializer='glorot_uniform'))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 1.2679 - acc: 0.4437 - val_loss: 1.1566 - val_acc: 0.4774\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.9006 - acc: 0.6366 - val_loss: 0.8959 - val_acc: 0.6715\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 97s 13ms/step - loss: 0.6396 - acc: 0.7518 - val_loss: 0.7133 - val_acc: 0.7194\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 92s 12ms/step - loss: 0.5221 - acc: 0.7748 - val_loss: 0.6854 - val_acc: 0.7262\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.4422 - acc: 0.8089 - val_loss: 0.6795 - val_acc: 0.7458\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.3255 - acc: 0.8780 - val_loss: 0.5078 - val_acc: 0.8351\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.2210 - acc: 0.9251 - val_loss: 0.4889 - val_acc: 0.8497\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1887 - acc: 0.9347 - val_loss: 0.3643 - val_acc: 0.8714\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 97s 13ms/step - loss: 0.1763 - acc: 0.9388 - val_loss: 0.4395 - val_acc: 0.8809\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.1652 - acc: 0.9410 - val_loss: 0.2877 - val_acc: 0.9084\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 113s 15ms/step - loss: 0.1468 - acc: 0.9453 - val_loss: 0.3279 - val_acc: 0.9030\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 100s 14ms/step - loss: 0.1488 - acc: 0.9431 - val_loss: 0.2493 - val_acc: 0.9114\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 86s 12ms/step - loss: 0.1300 - acc: 0.9486 - val_loss: 0.3047 - val_acc: 0.9114\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 91s 12ms/step - loss: 0.1345 - acc: 0.9489 - val_loss: 0.2884 - val_acc: 0.9148\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.1297 - acc: 0.9506 - val_loss: 0.2648 - val_acc: 0.9040\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.1312 - acc: 0.9499 - val_loss: 0.3083 - val_acc: 0.9101\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1242 - acc: 0.9508 - val_loss: 0.3764 - val_acc: 0.8948\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1228 - acc: 0.9523 - val_loss: 0.3594 - val_acc: 0.9155\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 88s 12ms/step - loss: 0.1291 - acc: 0.9493 - val_loss: 0.4166 - val_acc: 0.8924\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 85s 11ms/step - loss: 0.1255 - acc: 0.9525 - val_loss: 0.2394 - val_acc: 0.9257\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 84s 11ms/step - loss: 0.1245 - acc: 0.9514 - val_loss: 0.4621 - val_acc: 0.9006\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 84s 11ms/step - loss: 0.1295 - acc: 0.9518 - val_loss: 0.5215 - val_acc: 0.8924\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 86s 12ms/step - loss: 0.1175 - acc: 0.9531 - val_loss: 0.3417 - val_acc: 0.9148\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 85s 12ms/step - loss: 0.1223 - acc: 0.9521 - val_loss: 0.5034 - val_acc: 0.8846\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 85s 12ms/step - loss: 0.1106 - acc: 0.9558 - val_loss: 0.4166 - val_acc: 0.9040\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1176 - acc: 0.9547 - val_loss: 0.3414 - val_acc: 0.9196\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1112 - acc: 0.9539 - val_loss: 0.2972 - val_acc: 0.9162\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1168 - acc: 0.9551 - val_loss: 0.3276 - val_acc: 0.8931\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 82s 11ms/step - loss: 0.1129 - acc: 0.9548 - val_loss: 0.3930 - val_acc: 0.8924\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1073 - acc: 0.9576 - val_loss: 0.3393 - val_acc: 0.9237\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x229df2a20>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  0      415        53        4                   0   \n",
      "STANDING                 0       69       462        1                   0   \n",
      "WALKING                  0        0         0      481                  11   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 415   \n",
      "WALKING_UPSTAIRS         0        0         0       25                   7   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                           19  \n",
      "STANDING                           0  \n",
      "WALKING                            4  \n",
      "WALKING_DOWNSTAIRS                 4  \n",
      "WALKING_UPSTAIRS                 439  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33934266308311606, 0.9236511706820495]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "kernel_size = 3 #kernel_size of 1 worked surprisingly well\n",
    "pool_size = 2\n",
    "dropout_rate = 0.15\n",
    "f_act = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.goodaudience.com/predicting-physical-activity-based-on-smartphone-sensor-data-using-cnn-lstm-9182dd13b6bc\n",
    "first_model = Sequential()\n",
    "first_model.add(Conv1D(512, (kernel_size), input_shape=(X_train.shape[1],X_train.shape[2]), activation=f_act, padding='same'))\n",
    "first_model.add(BatchNormalization())\n",
    "first_model.add(MaxPooling1D(pool_size=(pool_size),padding='same'))\n",
    "first_model.add(Dropout(dropout_rate))\n",
    "first_model.add(Conv1D(64, (kernel_size), activation=f_act, padding='same'))\n",
    "first_model.add(BatchNormalization())\n",
    "first_model.add(MaxPooling1D(pool_size=(pool_size),padding='same'))\n",
    "first_model.add(Dropout(dropout_rate))\n",
    "first_model.add(Conv1D(32, (kernel_size), activation=f_act, padding='same'))\n",
    "first_model.add(BatchNormalization())\n",
    "first_model.add(MaxPooling1D(pool_size=(pool_size),padding='same'))\n",
    "first_model.add(LSTM(128, return_sequences=True))\n",
    "first_model.add(LSTM(128, return_sequences=True))\n",
    "first_model.add(LSTM(128))\n",
    "first_model.add(Dropout(dropout_rate))\n",
    "first_model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"best_model_weights2.hdf5\"\n",
    "checkpoint=ModelCheckpoint(filepath,monitor='val_acc',verbose=1,save_best_only=True,mode='max')\n",
    "callbacks_list =[checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 189s 26ms/step - loss: 0.8546 - acc: 0.7296 - val_loss: 0.6212 - val_acc: 0.7913\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.79131, saving model to best_model_weights2.hdf5\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 187s 25ms/step - loss: 0.3340 - acc: 0.9029 - val_loss: 0.2809 - val_acc: 0.8996\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.79131 to 0.89956, saving model to best_model_weights2.hdf5\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 188s 26ms/step - loss: 0.1964 - acc: 0.9354 - val_loss: 0.3422 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89956\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 187s 25ms/step - loss: 0.1614 - acc: 0.9427 - val_loss: 0.2332 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.89956 to 0.90601, saving model to best_model_weights2.hdf5\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 186s 25ms/step - loss: 0.1487 - acc: 0.9433 - val_loss: 0.2262 - val_acc: 0.9230\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.90601 to 0.92297, saving model to best_model_weights2.hdf5\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 187s 25ms/step - loss: 0.1369 - acc: 0.9494 - val_loss: 0.2627 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.92297\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 186s 25ms/step - loss: 0.1404 - acc: 0.9437 - val_loss: 0.2820 - val_acc: 0.8867\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.92297\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 188s 26ms/step - loss: 0.1328 - acc: 0.9474 - val_loss: 0.2842 - val_acc: 0.8843\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92297\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 188s 26ms/step - loss: 0.1249 - acc: 0.9494 - val_loss: 0.1911 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.92297 to 0.92331, saving model to best_model_weights2.hdf5\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 186s 25ms/step - loss: 0.1266 - acc: 0.9448 - val_loss: 0.2054 - val_acc: 0.9199\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92331\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 188s 26ms/step - loss: 0.1246 - acc: 0.9474 - val_loss: 0.1610 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.92331 to 0.94435, saving model to best_model_weights2.hdf5\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 187s 25ms/step - loss: 0.1199 - acc: 0.9524 - val_loss: 0.1598 - val_acc: 0.9281\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.94435\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 187s 26ms/step - loss: 0.1162 - acc: 0.9502 - val_loss: 0.1695 - val_acc: 0.9243\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.94435\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 188s 26ms/step - loss: 0.1178 - acc: 0.9505 - val_loss: 0.1711 - val_acc: 0.9471\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.94435 to 0.94706, saving model to best_model_weights2.hdf5\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 186s 25ms/step - loss: 0.1190 - acc: 0.9517 - val_loss: 0.1670 - val_acc: 0.9488\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.94706 to 0.94876, saving model to best_model_weights2.hdf5\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 189s 26ms/step - loss: 0.1132 - acc: 0.9506 - val_loss: 0.1744 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.94876\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 187s 25ms/step - loss: 0.1103 - acc: 0.9533 - val_loss: 0.1637 - val_acc: 0.9460\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.94876\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 188s 26ms/step - loss: 0.1069 - acc: 0.9544 - val_loss: 0.1876 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.94876\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 187s 25ms/step - loss: 0.1100 - acc: 0.9543 - val_loss: 0.1789 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.94876\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 188s 26ms/step - loss: 0.1087 - acc: 0.9535 - val_loss: 0.2038 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.94876\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 187s 25ms/step - loss: 0.1016 - acc: 0.9544 - val_loss: 0.1738 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.94876\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 187s 25ms/step - loss: 0.1024 - acc: 0.9565 - val_loss: 0.1886 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.94876\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 188s 26ms/step - loss: 0.1010 - acc: 0.9559 - val_loss: 0.2019 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.94876\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 188s 26ms/step - loss: 0.0990 - acc: 0.9546 - val_loss: 0.1870 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.94876\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 192s 26ms/step - loss: 0.1016 - acc: 0.9561 - val_loss: 0.2100 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.94876\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 194s 26ms/step - loss: 0.1018 - acc: 0.9551 - val_loss: 0.2093 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.94876\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 196s 27ms/step - loss: 0.1056 - acc: 0.9527 - val_loss: 0.1875 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.94876\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 193s 26ms/step - loss: 0.0994 - acc: 0.9570 - val_loss: 0.1794 - val_acc: 0.9362\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.94876\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 194s 26ms/step - loss: 0.0971 - acc: 0.9578 - val_loss: 0.2596 - val_acc: 0.9141\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.94876\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 195s 26ms/step - loss: 0.0937 - acc: 0.9593 - val_loss: 0.1976 - val_acc: 0.9386\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.94876\n"
     ]
    }
   ],
   "source": [
    "history=first_model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,callbacks=callbacks_list,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING THE PREVIOUSLY STORED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.goodaudience.com/predicting-physical-activity-based-on-smartphone-sensor-data-using-cnn-lstm-9182dd13b6bc\n",
    "first_model = Sequential()\n",
    "first_model.add(Conv1D(512, (kernel_size), input_shape=(X_train.shape[1],X_train.shape[2]), activation=f_act, padding='same'))\n",
    "first_model.add(BatchNormalization())\n",
    "first_model.add(MaxPooling1D(pool_size=(pool_size),padding='same'))\n",
    "first_model.add(Dropout(dropout_rate))\n",
    "first_model.add(Conv1D(64, (kernel_size), activation=f_act, padding='same'))\n",
    "first_model.add(BatchNormalization())\n",
    "first_model.add(MaxPooling1D(pool_size=(pool_size),padding='same'))\n",
    "first_model.add(Dropout(dropout_rate))\n",
    "first_model.add(Conv1D(32, (kernel_size), activation=f_act, padding='same'))\n",
    "first_model.add(BatchNormalization())\n",
    "first_model.add(MaxPooling1D(pool_size=(pool_size),padding='same'))\n",
    "first_model.add(LSTM(128, return_sequences=True))\n",
    "first_model.add(LSTM(128, return_sequences=True))\n",
    "first_model.add(LSTM(128))\n",
    "first_model.add(Dropout(dropout_rate))\n",
    "first_model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model.load_weights(\"best_model_weights2.hdf5\")#loading the weights from saved file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  2      418        64        0                   0   \n",
      "STANDING                 0       62       470        0                   0   \n",
      "WALKING                  0        0         0      496                   0   \n",
      "WALKING_DOWNSTAIRS       0        0         0       12                 406   \n",
      "WALKING_UPSTAIRS         0        0         0        1                   1   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            7  \n",
      "STANDING                           0  \n",
      "WALKING                            0  \n",
      "WALKING_DOWNSTAIRS                 2  \n",
      "WALKING_UPSTAIRS                 469  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,first_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 22s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "score = first_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16700983426927404, 0.9487614523243977]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+---------------------+--------------------+\n",
      "|         Model          |      Test_loss      |   Test_Accuracy    |\n",
      "+------------------------+---------------------+--------------------+\n",
      "|        LSTM(32)        |  0.3903591258076538 | 0.8948082796063793 |\n",
      "|        LSTM(64)        | 0.46545276161816074 | 0.8941296233457754 |\n",
      "|       LSTM(128)        |  0.3158544494973829 | 0.8988802171700034 |\n",
      "| LSTM(128)-Dropout(0.4) |  0.3383634945306286 | 0.8781812012215813 |\n",
      "|   LSTM(32)-LSTM(20)    |  0.3393426630831160 | 0.9236511706820495 |\n",
      "|      CONV1D-LSTM       | 0.16700983426927404 | 0.9487614523243977 |\n",
      "+------------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "Z=PrettyTable()\n",
    "Z.field_names = [\"Model\",\"Test_loss\",\"Test_Accuracy\"]\n",
    "Z.add_row([\"LSTM(32)\",\"0.3903591258076538\", \"0.8948082796063793\"])\n",
    "Z.add_row([\"LSTM(64)\",\"0.46545276161816074\",\"0.8941296233457754\"])\n",
    "Z.add_row([\"LSTM(128)\",\"0.3158544494973829\",\"0.8988802171700034\"])\n",
    "Z.add_row([\"LSTM(128)-Dropout(0.4)\",\"0.3383634945306286\", \"0.8781812012215813\"])\n",
    "Z.add_row([\"LSTM(32)-LSTM(20)\",\"0.3393426630831160\",\"0.9236511706820495\"])\n",
    "Z.add_row([\"CONV1D-LSTM\",\"0.16700983426927404\",\"0.9487614523243977\"])\n",
    "\n",
    "\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First we tried with single lstm layer to improve the accuracy.\n",
    "\n",
    "2. Because of small number of data points if we use more number of lstms model is very easiliy leads to overfitting.\n",
    "    \n",
    "3. Even After Experimenting with various number of lstms and dropouts also we are not able to improve accuracy  significantly.\n",
    "\n",
    "4. After That we used 2 layer lstm to tackle the problem.But not successful in improving accuaracy.\n",
    "\n",
    "5. we used conv1d with lstm to improve model's performance.\n",
    "\n",
    "6. we used 3 convolutional Layers and 3 lstm layers in model's architecture.\n",
    "\n",
    "7. And used The keras callback feature To save the best model in all the epochs.\n",
    "\n",
    "8. Best Model is with the accuracy 94.88%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
